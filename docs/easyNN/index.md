Andrew Ng has made Neural networks an extremely approachable subject for masses through the intuitive explanations of complex proecesses and mathematical equations needed to understand and use neural networks using his course here https://www.coursera.org/learn/machine-learning-course/. This has inspired me to develop EasyNN, an implementation of Neural networks from scratch in C++, to demonstrate it is only only very easy to understand and use neural networks, as shown by Andrew Ng, but it is also very easy to implement it from scratch.

EasyNN is based on the premise that it is really easy to implement neural networks from scratch, hence we would be focusing on the details of the implementation and make certain assumptions that include

* The reader has very good understanding of the concepts of neural networks, preferably from Andre Ng's course referred above.
* The reader has prior experience of programming. Knowledge of C++ will be helpful but accompanying explanation would allow non-C++ programming to easily understand the implementation details.

We will not be discussing the neural networks concepts, as they have already been very well explained by Andrew. Rather, they would be limited only to the extent that are needed for implementation. As Coursera terms and conditions do not allow sharing my the original material, hence we would be using the same equations as shown in the lectures and reproducing them for the discussion and implement the code accordingly.

### [Linear Regression](./LinearRegression.md)

### [Classification using Logistic Regression](./LogisticRegression.md)

### [Gradient Descent](./GradientDescent.md)


Hello World
Heading style 2
## $J(\theta) = \frac{1}{2m} \sum_{i=1}^{n} (h(x^{(i)}) - y^{(i)})^2$

Latex large
${\large J(\theta) = \frac{1}{2m} \sum_{i=1}^{n} (h(x^{(i)}) - y^{(i)})^2}$

$\large{J(\theta) = \frac{1}{2m} \sum_{i=1}^{n} (h(x^{(i)}) - y^{(i)})^2}$

Latex Large
${\Large J(\theta) = \frac{1}{2m} \sum_{i=1}^{n} (h(x^{(i)}) - y^{(i)})^2}$

$\Large{J(\theta) = \frac{1}{2m} \sum_{i=1}^{n} (h(x^{(i)}) - y^{(i)})^2}$

Latex huge
${\huge J(\theta) = \frac{1}{2m} \sum_{i=1}^{n} (h(x^{(i)}) - y^{(i)})^2}$

$\huge{J(\theta) = \frac{1}{2m} \sum_{i=1}^{n} (h(x^{(i)}) - y^{(i)})^2}$

Latex Huge
${\Huge J(\theta) = \frac{1}{2m} \sum_{i=1}^{n} (h(x^{(i)}) - y^{(i)})^2}$

$\Huge{J(\theta) = \frac{1}{2m} \sum_{i=1}^{n} (h(x^{(i)}) - y^{(i)})^2}$
